---
title: "The normal distribution"
output:
  pdf_document: default
  html_document:
    css: ./lab.css
    highlight: pygments
    theme: cerulean
---

In this lab we'll investigate the probability distribution that is most central
to statistics: the normal distribution.  If we are confident that our data are 
nearly normal, that opens the door to many powerful statistical methods.  Here 
we'll use the graphical tools of R to assess the normality of our data and also 
learn how to generate random numbers from a normal distribution.

## The Data

This week we'll be working with measurements of body dimensions.  This data set 
contains measurements from 247 men and 260 women, most of whom were considered 
healthy young adults.

```{r load-data, eval=TRUE}
setwd("C:/Users/Christophe/Documents/R/Lab3")
load("./more/bdims.RData")
```

Let's take a quick peek at the first few rows of the data.

```{r head-data, eval=TRUE}
head(bdims, n = 2)
```

You'll see that for every observation we have 25 measurements, many of which are
either diameters or girths.  A key to the variable names can be found at 
[http://www.openintro.org/stat/data/bdims.php](http://www.openintro.org/stat/data/bdims.php),
but we'll be focusing on just three columns to get started: weight in kg (`wgt`), 
height in cm (`hgt`), and `sex` (`1` indicates male, `0` indicates female).

Since males and females tend to have different body dimensions, it will be 
useful to create two additional data sets: one with only men and another with 
only women.

```{r male-female, eval=TRUE}
mdims <- subset(bdims, sex == 1)
fdims <- subset(bdims, sex == 0)
```

1.  Make a histogram of men's heights and a histogram of women's heights.  How 
    would you compare the various aspects of the two distributions?
    
```{r histogram_1, eval=TRUE}
hist(mdims$hgt)
hist(fdims$hgt)
```

> The height distribution of men appears to be normally distrubted at the median of ~170 and is bell-shaped and unimodal. 
Whereas, the distribution of females appear to be slightly right skewed with a median at ~165 but its unimodal. 

## The normal distribution

In your description of the distributions, did you use words like *bell-shaped* 
or *normal*?  It's tempting to say so when faced with a unimodal symmetric 
distribution.

To see how accurate that description is, we can plot a normal distribution curve 
on top of a histogram to see how closely the data follow a normal distribution. 
This normal curve should have the same mean and standard deviation as the data. 
We'll be working with women's heights, so let's store them as a separate object 
and then calculate some statistics that will be referenced later. 

```{r female-hgt-mean-sd, eval=TRUE}
fhgtmean <- mean(fdims$hgt)
fhgtsd   <- sd(fdims$hgt)
```

Next we make a density histogram to use as the backdrop and use the `lines` 
function to overlay a normal probability curve. The difference between a 
frequency histogram and a density histogram is that while in a frequency 
histogram the *heights* of the bars add up to the total number of observations, 
in a density histogram the *areas* of the bars add up to 1. The area of each bar 
can be calculated as simply the height *times* the width of the bar. Using a 
density histogram allows us to properly overlay a normal distribution curve over 
the histogram since the curve is a normal probability density function.
Frequency and density histograms both display the same exact shape; they only 
differ in their y-axis. You can verify this by comparing the frequency histogram 
you constructed earlier and the density histogram created by the commands below.

```{r hist-height, eval=TRUE}
hist(fdims$hgt, probability = TRUE, ylim = c(0,.06))
x <- 140:190
y <- dnorm(x = x, mean = fhgtmean, sd = fhgtsd)
lines(x = x, y = y, col = "blue")
```

After plotting the density histogram with the first command, we create the x- 
and y-coordinates for the normal curve.  We chose the `x` range as 140 to 190 in 
order to span the entire range of `fheight`.  To create `y`, we use `dnorm` to 
calculate the density of each of those x-values in a distribution that is normal
with mean `fhgtmean` and standard deviation `fhgtsd`.  The final command draws a
curve on the existing plot (the density histogram) by connecting each of the 
points specified by `x` and `y`. The argument `col` simply sets the color for 
the line to be drawn. If we left it out, the line would be drawn in black.

The top of the curve is cut off because the limits of the x- and y-axes are set 
to best fit the histogram.  To adjust the y-axis you can add a third argument to
the histogram function: `ylim = c(0, 0.06)`.

2.  Based on the this plot, does it appear that the data follow a nearly normal 
    distribution?

> The plot does show that the data follows a nearly normal distribution. 
It is unimodal and is symetrical around the median and is bell shaped. 

## Evaluating the normal distribution

Eyeballing the shape of the histogram is one way to determine if the data appear
to be nearly normally distributed, but it can be frustrating to decide just how 
close the histogram is to the curve. An alternative approach involves 
constructing a normal probability plot, also called a normal Q-Q plot for 
"quantile-quantile".

```{r qq, eval=TRUE}
qqnorm(fdims$hgt)
qqline(fdims$hgt)
```

A data set that is nearly normal will result in a probability plot where the 
points closely follow the line.  Any deviations from normality leads to 
deviations of these points from the line.  The plot for female heights shows 
points that tend to follow the line but with some errant points towards the 
tails.  We're left with the same problem that we encountered with the histogram 
above: how close is close enough?

A useful way to address this question is to rephrase it as: what do probability 
plots look like for data that I *know* came from a normal distribution?  We can 
answer this by simulating data from a normal distribution using `rnorm`.

```{r sim-norm, eval=TRUE}
sim_norm <- rnorm(n = length(fdims$hgt), mean = fhgtmean, sd = fhgtsd)
```

The first argument indicates how many numbers you'd like to generate, which we 
specify to be the same number of heights in the `fdims` data set using the 
`length` function.  The last two arguments determine the mean and standard 
deviation of the normal distribution from which the simulated sample will be 
generated.  We can take a look at the shape of our simulated data set, `sim_norm`, 
as well as its normal probability plot.

3.  Make a normal probability plot of `sim_norm`.  Do all of the points fall on 
    the line?  How does this plot compare to the probability plot for the real 
    data?
    
```{r 3, eval=TRUE}
qqnorm(sim_norm)
qqline(sim_norm)
```

> A majority of the points fall on the line but not all, there does appear to be outliers that do not fall exactly on the line. This plot compares to the probability plot for the real data by looking very similar and having a similar amount of data points falling on the line. 

Even better than comparing the original plot to a single plot generated from a 
normal distribution is to compare it to many more plots using the following 
function. It may be helpful to click the zoom button in the plot window.

```{r qqnormsim, eval=TRUE}
qqnormsim(fdims$hgt)
```

4.  Does the normal probability plot for `fdims$hgt` look similar to the plots 
    created for the simulated data?  That is, do plots provide evidence that the
    female heights are nearly normal?
  
  > `fdims$height` does appear similar to the plots created for normally distributed simulated data. The plots do provide evidence that the female heights are nearly normal because the QQ plots show the values falling on the line. 

5.  Using the same technique, determine whether or not female weights appear to 
    come from a normal distribution.
    
```{r on_your_own_5, eval = TRUE }
qqnormsim(fdims$wgt)
hist(fdims$wgt, probability = TRUE, ylim = c(0,.06))
wgtmean <- mean(fdims$wgt)
wgtsd <- sd(fdims$wgt)
x <- round(min(fdims$wgt),-1):round(max(fdims$wgt),-1)
y <- dnorm(x = x, mean = wgtmean, sd = wgtsd)
lines(x = x, y = y, col = "firebrick3")

```

> Based on the recently learned techinque of `qqnormsim` and then running it for `qqnormsim(fdims$wgt)` I can see that there is a lot of variability in the values falling on the line. It does not appear that the data is near normal. I further investigate the distribution by creating a density plot and adding a normal curve using the data values and it appears that the distribution is not nearly normal. 

## Normal probabilities

Okay, so now you have a slew of tools to judge whether or not a variable is 
normally distributed.  Why should we care?

It turns out that statisticians know a lot about the normal distribution.  Once 
we decide that a random variable is approximately normal, we can answer all 
sorts of questions about that variable related to probability.  Take, for 
example, the question of, "What is the probability that a randomly chosen young 
adult female is taller than 6 feet (about 182 cm)?" (The study that published
this data set is clear to point out that the sample was not random and therefore 
inference to a general population is not suggested.  We do so here only as an
exercise.)

If we assume that female heights are normally distributed (a very close 
approximation is also okay), we can find this probability by calculating a Z 
score and consulting a Z table (also called a normal probability table).  In R, 
this is done in one step with the function `pnorm`.

```{r pnorm, eval=TRUE}
1 - pnorm(q = 182, mean = fhgtmean, sd = fhgtsd)
```

Note that the function `pnorm` gives the area under the normal curve below a 
given value, `q`, with a given mean and standard deviation.  Since we're 
interested in the probability that someone is taller than 182 cm, we have to 
take one minus that probability.

Assuming a normal distribution has allowed us to calculate a theoretical 
probability.  If we want to calculate the probability empirically, we simply 
need to determine how many observations fall above 182 then divide this number 
by the total sample size.

```{r probability, eval=TRUE}
sum(fdims$hgt > 182) / length(fdims$hgt)
```

Although the probabilities are not exactly the same, they are reasonably close. 
The closer that your distribution is to being normal, the more accurate the 
theoretical probabilities will be.

6.  Write out two probability questions that you would like to answer; one 
    regarding female heights and one regarding female weights.  Calculate the 
    those probabilities using both the theoretical normal distribution as well 
    as the empirical distribution (four probabilities in all).  Which variable,
    height or weight, had a closer agreement between the two methods?
    
```{r q6_functions, eval=TRUE}

convert_pounds_to_kilo <- function(x){
                          x <- x/2.20462
                          return(x)
                          }

convert_feet_to_centimeters <- function(x){ 
                                x <- x * 30.48
                                return(x)
                                }
```

```{r q6, eval=TRUE, results='asis'}
library(scales)

paste("What is the probability that a randomly chosen young adult", 
      " female is heavier than 180 lbs?")

x_1 <- 1 - pnorm(q = convert_pounds_to_kilo(180), 
                 mean = mean(fdims$wgt), 
                 sd = sd(fdims$wgt))

paste("The probability of a randomly chosen young adult",
      "female is heavier than 180 lbs", 
      "using the theoretical normal distribution is", 
      percent(x_1), sep = " ")

y_1 <- subset(fdims, fdims$wgt > convert_pounds_to_kilo(180))

y_1 <- length(y_1$wgt) / length(fdims$wgt)

paste("The probability of a randomly chosen young adult",
      "female is heavier than 180 lbs", 
      "using the empirical method is", 
      percent(y_1), sep = " ")

paste("What is the probability that a randomly chosen young adult", 
      " female is smaller than 5 feet?")

x_2 <- pnorm(q = convert_feet_to_centimeters(5), 
             mean = mean(fdims$hgt), 
             sd = sd(fdims$hgt))

paste("The probability of a randomly chosen young adult",
      "female is smaller than 5 feet", 
      "using the theoretical normal distribution is", 
      percent(x_2), sep = " ")

y_2 <- subset(fdims, fdims$hgt < convert_feet_to_centimeters(5))

y_2 <- length(y_2$hgt) / length(fdims$hgt)

paste("The probability of a randomly chosen young adult",
      "female is smaller than 5 feet", 
      "using the empirical method is", 
      percent(y_2), sep = " ")

question_1_difference <- percent(abs(x_1 - y_1))
question_2_difference <- percent(abs(x_2 - y_2))

best_answer <- if((question_1_difference > question_2_difference)){ 
                  c("the height measurement was closer")
                  }else {
                  c("the weight measurement was closer")  
                  }

paste("The difference in percentages in the weight question is", question_1_difference, 
      "and the difference in percentages in the height question is", question_2_difference, 
      "and therefore", best_answer, sep = " ")

```


* * *

## On Your Own

-   Now let's consider some of the other variables in the body dimensions data 
    set.  Using the figures at the end of the exercises, match the histogram to 
    its normal probability plot.  All of the variables have been standardized 
    (first subtract the mean, then divide by the standard deviation), so the 
    units won't be of any help.  If you are uncertain based on these figures, 
    generate the plots in R to check.
    
```{r function_lab3, eval = TRUE}
standardize_lab3 <- function(x){
  x <- x - mean(x)
  x <- x / sd(x)
 return(x)
 }
```

---

**a.** The histogram for female biiliac (pelvic) diameter (`bii.di`) belongs
    to normal probability plot letter `plot B`.

```{r on_your_own_a, eval = TRUE}
standardized_bii.di <- standardize_lab3(fdims$bii.di)
qqnorm(standardized_bii.di)
qqline(standardized_bii.di)

```


**b.** The histogram for female elbow diameter (`elb.di`) belongs to normal 
    probability plot letter `plot C`.
    
```{r on_your_own_b, eval=TRUE}
standardized_elb.di <- standardize_lab3(fdims$elb.di)
qqnorm(standardized_elb.di)
qqline(standardized_elb.di)

```
    
**c.** The histogram for general age (`age`) belongs to normal probability 
    plot letter `plot D`.
    
```{r on_your_own_c, eval=TRUE}
standardized_age <- standardize_lab3(bdims$age)
qqnorm(standardized_age)
qqline(standardized_age)
```

**d.** The histogram for female chest depth (`che.de`) belongs to normal 
    probability plot letter `plot A`. 
    
```{r on_your_own_d, eval = TRUE}
standardized_che.de <- standardize_lab3(fdims$che.de)
qqnorm(standardized_che.de)
qqline(standardized_che.de)
```

-   Note that normal probability plots C and D have a slight stepwise pattern.  
    Why do you think this is the case?

> The stepwise pattern for plot D is clear in that age was recorded as a discrete variable as only the age in years was recorded. Therefore, there will be a clear 1 year step between each value. The stepwise pattern for C is less clear, it could be that elbows have a natural tendency to clump in certain values but that would be unusual. It could be that plot C has such a narrow range of values or the measurement is not precise enough for this small measure that we see clumping in certain values and the stepwise pattern. 

-   As you can see, normal probability plots can be used both to assess 
    normality and visualize skewness.  Make a normal probability plot for female 
    knee diameter (`kne.di`).  Based on this normal probability plot, is this 
    variable left skewed, symmetric, or right skewed?  Use a histogram to confirm 
    your findings.
    
> As the histogram below reveals the variable is right skewed and unimodal. There is a long tail on the left side of the graph indicating some outliers which may be of interest. 

```{r on_your_own_lastq, eval=TRUE}
d <- fdims$kne.di
hist(d, probability = TRUE, ylim = c(0,.5))
kne.di_mean <- mean(d)
kne.di_sd <- sd(d)
x <- round(min(d) - .5 ,0):round(max(d) + .5 ,0)
y <- dnorm(x = x, mean = kne.di_mean, sd = kne.di_sd)
lines(x = x, y = y, col = "firebrick3")
```

![histQQmatch](more/histQQmatch.png)

<div id="license">
This is a product of OpenIntro that is released under a 
[Creative Commons Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0). 
This lab was adapted for OpenIntro by Andrew Bray and Mine &Ccedil;etinkaya-Rundel
from a lab written by Mark Hansen of UCLA Statistics.
</div>
