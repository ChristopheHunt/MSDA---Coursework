---
title: "R Notebook"
output: html_notebook
---

```{r}
library(fma)
library(fpp)
```


HW  8.1

![](https://raw.githubusercontent.com/ChristopheHunt/MSDA---Coursework/master/Data%20624/Homework%206/8.1.image.PNG)

Figure 8.24 shows the ACFs for 36 random numbers, 360 random numbers and for 1,000 random numbers.

Explain the differences among these figures. Do they all indicate the data are white noise?

We can see that the correlation between previous observations are not exponentially decaying which does indicate these are white noise series. All the figures appear to have varying degrees of correlation with the first series having the highest and the last series having the lowest. 

Why are the critical values at different distances from the mean of zero? Why are the auto-correlations different in each figure when they each refer to white noise?

The critical values are determined from the sample size, since the size of each series is different the critical values are also different. The auto-correlations are based on the past values, since the time series are different in sample size the auto-correlations of each series will be different. 

HW  8.2

A classic example of a non-stationary series is the daily closing IBM stock prices (data set ibmclose). Use R to plot the daily closing prices for IBM stock and the ACF and PACF. Explain how each plot shows the series is non-stationary and should be differenced.

```{r}
library(fma)
data(ibmclose)
par(mfrow=c(1, 2))
plot(ibmclose)
plot(diff(ibmclose,1))
```

The plot of the time series shows trends over time and patters in the long term. The current value is highly correlated with the previous value. Adding a 1 day lag does should some promise in transforming the time series to reach stationarity but there looks to be some pattern between the 200 and 300 day marks. 

```{r}
par(mfrow=c(1, 3))
acf(ibmclose)
acf(diff(ibmclose,1))
```
The initial graph shows that the data series is most certainly not stationary as we see the exponential decay. Using the differcing of 1 order by 1 day the auto-correlation of the lags shows that the its close to reaching white noise. I have concerns about the marks reaching past the critical values beyond lag 1. 

```{r}
par(mfrow=c(1, 2))
pacf(ibmclose)
pacf(diff(ibmclose,1))
```

Interestingly, the PACF of the original time series suggests an AR(1) model but using differencing the model moves towards a MA(1) model. This is an interesting example of how differencing will transform a time series to be best suited by another model method. 

HW  8.6 

Consider the number of women murdered each year (per 100,000 standard population) in the United States (data set wmurders).

```{r}
data(wmurders)
```


a. By studying appropriate graphs of the series in R, find an appropriate ARIMA(p,d,q) model for these data.

```{r}
plot(wmurders)
```
There is a clear pattern in the data so we will need to apply differencing. Using the $ndiffs()$ method we see that `r ndiffs(wmurders)` order of differences is appropriate.

```{r}
plot(diff(wmurders, differences = 2))
```
```{r}
par(mfrow=c(1, 2))
acf(diff(wmurders, differences = 2))
pacf(diff(wmurders, differences = 2))
```

From the ACF plot and PACF plot we only see a significant positive spike at lag 1 for the ACF so I will conclude that an appropriate model is ARIMA(1,2,0). This seems appropriate as we try to avoid mixed ARIMA models.  

```{r}
arima(wmurders, order = c(1,2,0))
```

b. Should you include a constant in the model? Explain.

A constant is only included when our differencing order is equal to 0, since we have a differencing order of 2 we do not include a constant in the model. 

c. Write this model in terms of the backshift operator.

$(1-(-0.6719B))(1-B)2_{yt}$

d. Fit the model using R and examine the residuals. Is the model satisfactory?

```{r}
arima_1_2 <- arima(wmurders, order = c(1,2,0))
tsdiag(arima_1_2)
```

The residuals appear to have non-constant variance, my only concern is the appearance of a pattern from 1980 to 1995. Further investigation may yield more information for this time period. 

e. Forecast three times ahead. Check your forecasts by hand to make sure you know how they have been calculated.

```{r}
forecast(arima_1_2, h = 3)
```

$$Y_t = (1-\phi_1 B))(1-B)^2_{yt-1}$$ 

$$Y_t = 2y_{t-1} + y_{t-2} + -0.6719y_{t-1}$$
$$Y_t = (2 * 2.589383) - 2.662227 + -0.6719*(2.589383 - 2.662227)$$ 

```{r}
tail(wmurders)
```

f. Create a plot of the series with forecasts and prediction intervals for the next three periods shown.

```{r}
plot(forecast(arima_1_2, h = 3))
```

g. Does auto.arima give the same model you have chosen? If not, which model do you think is better?

```{r}
auto.arima(wmurders)
```

The auto.arima method does not give the same model but it does have a lower AICc score so we would choose the auto.arima method if our main concern was predictability. If the use case allowed for lower accuracy but better intereptability I would chose the model I developed since the AICc scores are not dramatically different and we have one less term. 


HW  8.8

Consider the total net generation of electricity (in billion kilowatt hours) by the U.S. electric industry (monthly for the period 1985-1996). (Data set usmelec.) In general there are two peaks per year: in mid-summer and mid-winter.

```{r}
data(usmelec)
usmelec <- window(usmelec, start = 1985, end = 1996)
plot(usmelec)
```

a. Examine the 12-month moving average of this series to see what kind of trend is involved.

```{r}
plot(ma(usmelec, order=12))
```

The 12 month moving average shows a clear upward trend with somewhat trivial mountains and valleys. 

b. Do the data need transforming? If so, find a suitable transformation.

```{r}
library(forecast)
BoxCox.lambda(usmelec)
```


The data could benefit from a BoxCox transformation to the power of -.5, however, I don't believe that we will see dramatic benefits to the transformation so I will forgo the transformation for the sake for interepetibility. A transformation that would be informative if the data was available would be a population adjustment since the growth of electrical needs could possibly be explained by the growth in population. 

c. Are the data stationary? If not, find an appropriate differencing which yields stationary data.

We will start with the kpss test, a p-value lower than .05 indicates that differencing is required. 

```{r}
kpss.test(usmelec)
```

```{r}
paste(nsdiffs(usmelec), "order of seasonal differences")
paste(ndiffs(nsdiffs(usmelec)), "order of differences")
```

An order of 1 seasonal differencing is necessary to reach stationarity with this time series.  

d. Identify a couple of ARIMA models that might be useful in describing the time series. Which of your models is the best according to their AIC values?

```{r}
par(mfrow=c(1, 2))
acf(diff(usmelec,  lag = 12, differences = 1))
pacf(diff(usmelec, lag = 12, differences = 1))
```

Based on the plots the ACF has a postive value at lag 1 and 2 for a non-seasonal MA(2) term, a positive value at PACF at lag 1 for a non-seasonal AR(1), and we know that we will only use a seasonal difference order of 1. The negative values at the first lag for the seasonal PACF and ACF suggest an AR(1) and MA(1) term but the ACF spike is just approaching significance 

```{r}
arima(usmelec, order = c(1,0,2), seasonal = c(1,1,1))
```

```{r}
arima(usmelec, order = c(1,0,2), seasonal = c(1,1,0))
```

```{r}
arima(usmelec, order = c(1,0,2), seasonal = c(0,1,1))
```

The best ARIMA model is ARIMA(1,0,2)(0,1,1)[12] based on the AIC score and interpetability 

e. Estimate the parameters of your best model and do diagnostic testing on the residuals. Do the residuals resemble white noise? If not, try to find another ARIMA model which fits better.

The parameters of the best model are as follows:

```{r}
fit <- arima(usmelec, order = c(1,0,2), seasonal = c(0,1,1))
summary(fit)
```

```{r}
tsdisplay(fit$residuals)
```

Since all the spikes are within significance limit the residuals do appear to be white noise. 

f. Forecast the next 15 years of generation of electricity by the U.S. electric industry. Get the latest figures from http://data.is/zgRWCO to check on the accuracy of your forecasts.

```{r}
plot(forecast(fit, h = (15*12)))
```

![](https://raw.githubusercontent.com/ChristopheHunt/MSDA---Coursework/master/Data%20624/Homework%206/Website%20Image.PNG)

"Electricity: Overview." DataMarket, datamarket.com/data/set/1d9r/electricity-overview#!display=line&ds=1d9r!x0z=8.

g. How many years of forecasts do you think are sufficiently accurate to be usable?

It depends on the use case, if this is just to have a high level understanding of the tragejectory it does that job well for a number of years. However, if accuracy is extremely important than the model has dimishing accuracy even after a few years. However, as best I can tell I believe its accuracte up to year 2000 so ~4 years is about the usuable forecast period for this model. 



