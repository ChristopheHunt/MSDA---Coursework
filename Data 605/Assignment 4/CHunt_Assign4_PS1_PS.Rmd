---
title: "Homework 4"
author: "Christophe Hunt"
date: "February 20, 2017"
output:
  pdf_document:
    fig_caption: yes
    keep_tex: yes
    includes:
      in_header: header.tex
    number_sections: yes
    toc: yes
    toc_depth: 2
  html_document:
    toc: yes
    toc_depth: '2'
---

# Problem Set 1 

In this problem, we'll verify using R that SVD and Eigenvalues are related as worked out in the weekly module. Given a 3 × 2 matrix A


\[
A = \begin{bmatrix}
    1 & 2 & 3 \\
   -1 & 0 & 4 
\end{bmatrix}
\]

## write code in R to compute X = AAT and Y = ATA. 

```{r}
A <- matrix(c(1,-1,2,0,3,4), nrow=2)
X <- A%*%t(A)
Y <- t(A)%*%A
list("X" = X, "Y" = Y)
```
\newpage

## Then, compute the eigenvalues and eigenvectors of X and Y using the built-in commads in R. 

```{r}
results <- list("X" = eigen(X))
results <- c(results, "Y" = eigen(Y))
results
```


## Then, compute the left-singular, singular values, and right-singular vectors of A using the svd command. 

```{r}
results <- svd(A)
names(results) <- c("singular", "left-singular", "right-singular")
results
```


## Examine the two sets of singular vectors and show that they are indeed eigenvectors of X and Y. 

```{r}
results$`left-singular`
X_vectors <- eigen(X)$vectors
X_vectors
```

We can see that the two sets of vectors are indeed eigenvectors of X and Y. Also, note that the sign switch does not impact the interpetation of the eigenvectors, we can multiply by -1 and it has no further impact.  

```{r}
results$`left-singular`
X_vectors[,1] <- (X_vectors[,1]*-1)
X_vectors
```

```{r}
results$`right-singular`
Y_vectors <- eigen(Y)$vectors
Y_vectors[,1] <- (Y_vectors[,1]*-1)
Y_vectors
```

# 2. Problem Set 2

Using the procedure outlined in section 1 of the weekly handout, write a function to compute the inverse of a well-conditioned full-rank square matrix using co-factors. In order to compute the co-factors, you may use built-in commands to compute the determinant. Your function should have the following signature: 

B = myinverse(A)

where A is a matrix and B is its inverse and A×B = I. The off-diagonal elements of I should be close to zero, if not zero. Likewise, the diagonal elements should be close to 1, if not 1. Small numerical precision errors are acceptable but the function myinverse should be correct and must use co-factors and determinant of A to compute the inverse. 

```{r, }
myinverse <- function(M){
              results <- list()
              results$original <- M 
              #save original to compare
              cofactors <- matrix(nrow = nrow(M), ncol = ncol(M)) 
              # create empty matrix to store cofactors
              for(i in 1:nrow(M)){ #loop over rows
                for (j in 1:ncol(M)) # loop over columns
                  cofactors[i,j] <- ((-1)^(i + j)*det(M[-i, -j])) 
                #for row, column; sign * determinate of submatrix
              }
              results$inverse <- t(cofactors)/det(M) 
              #transpose of cofactors matrix / determinate of original matrix
              return(results)
            }
```

```{r}
M <- matrix(c(1:7,12,20), nrow = 3)
myinverse(M)
```

